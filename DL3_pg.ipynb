{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sahiltambe18/DL_CLG/blob/main/DL3_pg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YJBuhoChrfE3",
    "outputId": "d5ecc221-f59f-4c03-ca58-b806fa8a302a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 1.6405 - accuracy: 0.3968 - val_loss: 1.3197 - val_accuracy: 0.5276\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 1.2695 - accuracy: 0.5514 - val_loss: 1.1240 - val_accuracy: 0.6090\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 1.1044 - accuracy: 0.6106 - val_loss: 1.0262 - val_accuracy: 0.6315\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.9937 - accuracy: 0.6562 - val_loss: 0.9135 - val_accuracy: 0.6761\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.9100 - accuracy: 0.6840 - val_loss: 0.9121 - val_accuracy: 0.6868\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.8429 - accuracy: 0.7056 - val_loss: 0.8554 - val_accuracy: 0.7045\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 0.7872 - accuracy: 0.7259 - val_loss: 0.8339 - val_accuracy: 0.7122\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.7428 - accuracy: 0.7413 - val_loss: 0.7985 - val_accuracy: 0.7247\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 0.6965 - accuracy: 0.7575 - val_loss: 0.8042 - val_accuracy: 0.7276\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.6604 - accuracy: 0.7683 - val_loss: 0.7702 - val_accuracy: 0.7425\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 22s 29ms/step - loss: 0.6239 - accuracy: 0.7816 - val_loss: 0.7955 - val_accuracy: 0.7337\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 22s 28ms/step - loss: 0.5938 - accuracy: 0.7901 - val_loss: 0.7802 - val_accuracy: 0.7457\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.5616 - accuracy: 0.8032 - val_loss: 0.7822 - val_accuracy: 0.7384\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.5321 - accuracy: 0.8138 - val_loss: 0.8159 - val_accuracy: 0.7431\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 21s 27ms/step - loss: 0.5029 - accuracy: 0.8221 - val_loss: 0.8505 - val_accuracy: 0.7393\n",
      "313/313 - 2s - loss: 0.8505 - accuracy: 0.7393 - 2s/epoch - 6ms/step\n",
      "Test accuracy: 0.7393\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load and preprocess data\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "cifar_dir = \"D:\\Work\\python\\dl_clg\\datasets\\cifar10\\cifar-10-batches-py\"\n",
    "def load_cifar10_batch(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        images = batch['data']\n",
    "        labels = batch['labels']\n",
    "        images = images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Reformat to (num_samples, 32, 32, 3)\n",
    "        return images, np.array(labels)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(1, 6):\n",
    "    images, labels = load_cifar10_batch(os.path.join(cifar_dir, f\"data_batch_{i}\"))\n",
    "    x_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "# Combine all batches into a single array\n",
    "x_train = np.concatenate(x_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# Load test batch\n",
    "x_test, y_test = load_cifar10_batch(os.path.join(cifar_dir, \"test_batch\"))\n",
    "\n",
    "# Normalize the pixel values\n",
    "x_train, x_test = x_train.astype('float32') / 255.0, x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=15, batch_size=64, \n",
    "                    validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE0sS09PvFOL"
   },
   "source": [
    "\n",
    "1. Image Classification:\n",
    "Image classification is the task of categorizing images into predefined classes. Here's how it works:\n",
    "\n",
    "- Input: An image is represented as a 3D array of numbers (height × width × channels)\n",
    "- For RGB images: 3 channels (Red, Green, Blue), each pixel value ranges from 0-255\n",
    "- Preprocessing: Normalize values (usually to 0-1 range), resize images, augment data\n",
    "- Feature Extraction: Extract important patterns and features from images\n",
    "- Classification: Map these features to specific output classes using a trained model\n",
    "\n",
    "2. CNN in Image Classification:\n",
    "CNNs (Convolutional Neural Networks) are specialized neural networks for processing grid-like data (images). Here's a typical CNN architecture:\n",
    "\n",
    "Key CNN components:\n",
    "- **Convolutional Layer**: Applies filters to detect features (edges, textures, patterns)\n",
    "- **Pooling Layer**: Reduces spatial dimensions while retaining important information\n",
    "- **Activation Functions**: Adds non-linearity (ReLU is commonly used)\n",
    "- **Fully Connected Layers**: Final classification based on extracted features\n",
    "\n",
    "3. PyDrive:\n",
    "PyDrive is a wrapper library for Google Drive API that simplifies:\n",
    "- Authentication with Google Drive\n",
    "- File upload/download operations\n",
    "- File management (create, delete, move)\n",
    "- File sharing and permissions\n",
    "\n",
    "Example usage:\n",
    "```python\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "# Authenticate\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Upload file\n",
    "file = drive.CreateFile({'title': 'test.txt'})\n",
    "file.SetContentString('Hello World!')\n",
    "file.Upload()\n",
    "```\n",
    "\n",
    "4. tqdm:\n",
    "tqdm is a progress bar library that shows:\n",
    "- Progress of iterations (loops, data loading)\n",
    "- Estimated time remaining\n",
    "- Current speed of iteration\n",
    "- Total time elapsed\n",
    "\n",
    "Example usage:\n",
    "```python\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Simple loop with progress bar\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# With data loading\n",
    "for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "    # process batch\n",
    "    pass\n",
    "```\n",
    "\n",
    "5. Keras Layers:\n",
    "\n",
    "A. Dense Layer:\n",
    "```python\n",
    "# Fully connected layer\n",
    "layers.Dense(units=64, activation='relu')\n",
    "```\n",
    "- Each neuron connected to all neurons in previous layer\n",
    "- Used for: Final classification, feature combination\n",
    "- Parameters:\n",
    "  - units: Number of neurons\n",
    "  - activation: Activation function\n",
    "  - input_shape: Required for first layer\n",
    "\n",
    "B. Flatten Layer:\n",
    "```python\n",
    "# Convert multi-dimensional input to 1D\n",
    "layers.Flatten()\n",
    "```\n",
    "- Converts 2D/3D input to 1D vector\n",
    "- No parameters to learn\n",
    "- Used between Conv layers and Dense layers\n",
    "- Example: (batch_size, 7, 7, 64) → (batch_size, 3136)\n",
    "\n",
    "C. Dropout Layer:\n",
    "```python\n",
    "# Randomly disable neurons during training\n",
    "layers.Dropout(rate=0.5)\n",
    "```\n",
    "- Prevents overfitting\n",
    "- Randomly deactivates neurons during training\n",
    "- rate: Fraction of units to drop (e.g., 0.5 = 50%)\n",
    "- Only active during training, not during inference\n",
    "\n",
    "Here's a complete example combining these layers:\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten for dense layers\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Dense layers with dropout\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Output layer\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "Each layer type has its specific purpose:\n",
    "- Dense: Final classification, feature combination\n",
    "- Flatten: Dimension reduction for Dense layers\n",
    "- Dropout: Regularization, preventing overfitting\n",
    "- Conv2D: Feature extraction from images\n",
    "- MaxPooling2D: Dimension reduction, feature selection\n",
    "\n",
    "The combination of these layers allows the network to:\n",
    "1. Extract features from raw images\n",
    "2. Combine these features meaningfully\n",
    "3. Prevent overfitting during training\n",
    "4. Make final classifications effectively"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPirkD3vHTUe8MCPHORHeKd",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
