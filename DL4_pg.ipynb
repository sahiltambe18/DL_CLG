{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sahiltambe18/DL_CLG/blob/main/DL3_pg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "IMG_SIZE = (32,32)\n",
    "BATCH_SIZE = 32\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(data_dir):\n",
    "    \n",
    "    \n",
    "    traindata = data_generator.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    return traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # Output layer for 10 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"D:\\Work\\python\\dl_clg\\datasets\\cifar10\\cifar10_dataset\"\n",
    "traindata = getData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 296s 157ms/step - loss: 1.5985 - accuracy: 0.4095\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 194s 104ms/step - loss: 1.2365 - accuracy: 0.5609\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 289s 154ms/step - loss: 1.0826 - accuracy: 0.6214\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 233s 124ms/step - loss: 0.9799 - accuracy: 0.6586\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.9096 - accuracy: 0.6852\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(traindata, epochs=5  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE0sS09PvFOL"
   },
   "source": [
    "\n",
    "1. Image Classification:\n",
    "Image classification is the task of categorizing images into predefined classes. Here's how it works:\n",
    "\n",
    "- Input: An image is represented as a 3D array of numbers (height × width × channels)\n",
    "- For RGB images: 3 channels (Red, Green, Blue), each pixel value ranges from 0-255\n",
    "- Preprocessing: Normalize values (usually to 0-1 range), resize images, augment data\n",
    "- Feature Extraction: Extract important patterns and features from images\n",
    "- Classification: Map these features to specific output classes using a trained model\n",
    "\n",
    "2. CNN in Image Classification:\n",
    "CNNs (Convolutional Neural Networks) are specialized neural networks for processing grid-like data (images). Here's a typical CNN architecture:\n",
    "\n",
    "Key CNN components:\n",
    "- **Convolutional Layer**: Applies filters to detect features (edges, textures, patterns)\n",
    "- **Pooling Layer**: Reduces spatial dimensions while retaining important information\n",
    "- **Activation Functions**: Adds non-linearity (ReLU is commonly used)\n",
    "- **Fully Connected Layers**: Final classification based on extracted features\n",
    "\n",
    "3. PyDrive:\n",
    "PyDrive is a wrapper library for Google Drive API that simplifies:\n",
    "- Authentication with Google Drive\n",
    "- File upload/download operations\n",
    "- File management (create, delete, move)\n",
    "- File sharing and permissions\n",
    "\n",
    "Example usage:\n",
    "```python\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "# Authenticate\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Upload file\n",
    "file = drive.CreateFile({'title': 'test.txt'})\n",
    "file.SetContentString('Hello World!')\n",
    "file.Upload()\n",
    "```\n",
    "\n",
    "4. tqdm:\n",
    "tqdm is a progress bar library that shows:\n",
    "- Progress of iterations (loops, data loading)\n",
    "- Estimated time remaining\n",
    "- Current speed of iteration\n",
    "- Total time elapsed\n",
    "\n",
    "Example usage:\n",
    "```python\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Simple loop with progress bar\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# With data loading\n",
    "for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "    # process batch\n",
    "    pass\n",
    "```\n",
    "\n",
    "5. Keras Layers:\n",
    "\n",
    "A. Dense Layer:\n",
    "```python\n",
    "# Fully connected layer\n",
    "layers.Dense(units=64, activation='relu')\n",
    "```\n",
    "- Each neuron connected to all neurons in previous layer\n",
    "- Used for: Final classification, feature combination\n",
    "- Parameters:\n",
    "  - units: Number of neurons\n",
    "  - activation: Activation function\n",
    "  - input_shape: Required for first layer\n",
    "\n",
    "B. Flatten Layer:\n",
    "```python\n",
    "# Convert multi-dimensional input to 1D\n",
    "layers.Flatten()\n",
    "```\n",
    "- Converts 2D/3D input to 1D vector\n",
    "- No parameters to learn\n",
    "- Used between Conv layers and Dense layers\n",
    "- Example: (batch_size, 7, 7, 64) → (batch_size, 3136)\n",
    "\n",
    "C. Dropout Layer:\n",
    "```python\n",
    "# Randomly disable neurons during training\n",
    "layers.Dropout(rate=0.5)\n",
    "```\n",
    "- Prevents overfitting\n",
    "- Randomly deactivates neurons during training\n",
    "- rate: Fraction of units to drop (e.g., 0.5 = 50%)\n",
    "- Only active during training, not during inference\n",
    "\n",
    "Here's a complete example combining these layers:\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten for dense layers\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Dense layers with dropout\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Output layer\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "Each layer type has its specific purpose:\n",
    "- Dense: Final classification, feature combination\n",
    "- Flatten: Dimension reduction for Dense layers\n",
    "- Dropout: Regularization, preventing overfitting\n",
    "- Conv2D: Feature extraction from images\n",
    "- MaxPooling2D: Dimension reduction, feature selection\n",
    "\n",
    "The combination of these layers allows the network to:\n",
    "1. Extract features from raw images\n",
    "2. Combine these features meaningfully\n",
    "3. Prevent overfitting during training\n",
    "4. Make final classifications effectively"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPirkD3vHTUe8MCPHORHeKd",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
