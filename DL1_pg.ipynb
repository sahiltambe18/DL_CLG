{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eF-3JfJd-2mE",
    "outputId": "612f1828-418a-41e8-da07-9a0058e383cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Generate synthetic data\n",
    "torch.manual_seed(0)\n",
    "X_train = torch.rand(100, 1)\n",
    "y_train = 2 * X_train + 3 + torch.randn(100, 1) * 0.1\n",
    "\n",
    "# Define a simple linear model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test model prediction\n",
    "X_test = torch.tensor([[1.0]])\n",
    "y_pred = model(X_test)\n",
    "print(\"PyTorch Prediction for X=1.0:\", y_pred.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 3.1595\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.0222\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 558us/step - loss: 2.8924\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7697\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6536\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5440\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4403\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3422\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2495\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1619\n",
      "Predicition tf.Tensor(\n",
      "[[ 0.58623695]\n",
      " [ 0.09560874]\n",
      " [ 2.3533278 ]\n",
      " [-2.2135217 ]\n",
      " [-1.0893991 ]\n",
      " [ 0.8726798 ]\n",
      " [-2.271839  ]\n",
      " [ 0.5263802 ]\n",
      " [-1.256078  ]\n",
      " [ 0.5776342 ]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "x=tf.random.normal((10,2))\n",
    "y=tf.random.normal((10,1))\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "tf.keras.layers.Dense(1,input_dim=2)\n",
    "])\n",
    "model.compile(optimizer='sgd',loss='mse')\n",
    "model.fit(x,y,epochs=10)\n",
    "print(\"Predicition\",model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1AkzH7PA9RS"
   },
   "source": [
    "\n",
    "1. What is a tensor?\n",
    "A tensor is a fundamental data structure used in deep learning - it's a generalization of vectors and matrices to potentially higher dimensions. Think of it as:\n",
    "- Scalar: 0-dimensional tensor (single number)\n",
    "- Vector: 1-dimensional tensor (list of numbers)\n",
    "- Matrix: 2-dimensional tensor (table of numbers)\n",
    "- N-dimensional array: Higher dimensional tensor\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Scalar (0D tensor)\n",
    "scalar = tf.constant(5)\n",
    "\n",
    "# Vector (1D tensor)\n",
    "vector = tf.constant([1, 2, 3, 4])\n",
    "\n",
    "# Matrix (2D tensor)\n",
    "matrix = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "# 3D tensor\n",
    "tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "```\n",
    "\n",
    "2. Dimensions and Ranks in TensorFlow:\n",
    "- Rank: Number of dimensions in a tensor\n",
    "- Shape: Length of each dimension\n",
    "\n",
    "Examples:\n",
    "```python\n",
    "# Rank 0 (scalar): shape []\n",
    "t0 = tf.constant(42)\n",
    "\n",
    "# Rank 1 (vector): shape [3]\n",
    "t1 = tf.constant([1, 2, 3])\n",
    "\n",
    "# Rank 2 (matrix): shape [2, 3]\n",
    "t2 = tf.constant([[1, 2, 3],\n",
    "                 [4, 5, 6]])\n",
    "\n",
    "# Rank 3: shape [2, 2, 2]\n",
    "t3 = tf.constant([[[1, 2], [3, 4]],\n",
    "                 [[5, 6], [7, 8]]])\n",
    "```\n",
    "\n",
    "3. Building Models in Keras:\n",
    "There are three main ways to build models in Keras:\n",
    "\n",
    "a. Sequential API (simplest):\n",
    "```python\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "b. Functional API (more flexible):\n",
    "```python\n",
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "inputs = Input(shape=(784,))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "\n",
    "c. Subclassing (most flexible):\n",
    "```python\n",
    "class CustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.dropout = layers.Dropout(0.2)\n",
    "        self.dense2 = layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense2(x)\n",
    "```\n",
    "\n",
    "4. Function Operations in Theano:\n",
    "Theano (though now deprecated) introduced several key concepts still used in modern frameworks:\n",
    "- Symbolic Variables: Placeholders for data\n",
    "- Computational Graphs: Operations arranged in a directed graph\n",
    "- Function Compilation: Converting symbolic expressions to efficient code\n",
    "\n",
    "Example of Theano-style operations (modern equivalent in TensorFlow):\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define variables\n",
    "x = tf.Variable(initial_value=3.0)\n",
    "y = tf.Variable(initial_value=2.0)\n",
    "\n",
    "# Define operation\n",
    "@tf.function  # Similar to Theano's function compilation\n",
    "def compute_z(x, y):\n",
    "    return tf.square(x) + y\n",
    "\n",
    "# Execute operation\n",
    "z = compute_z(x, y)\n",
    "```\n",
    "\n",
    "5. PyTorch vs TensorFlow Differences:\n",
    "\n",
    "Key Differences:\n",
    "1. Dynamic vs Static Graphs:\n",
    "```python\n",
    "# PyTorch (Dynamic)\n",
    "class PyTorchModel(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # Can modify behavior at runtime\n",
    "        if self.training:\n",
    "            return x * 2\n",
    "        return x\n",
    "\n",
    "# TensorFlow (Static with @tf.function)\n",
    "@tf.function\n",
    "def tensorflow_model(x):\n",
    "    # Graph is fixed after first run\n",
    "    return x * 2\n",
    "```\n",
    "\n",
    "2. Eager Execution:\n",
    "```python\n",
    "# PyTorch (Always eager by default)\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = x + 2  # Immediate execution\n",
    "\n",
    "# TensorFlow (Can switch between eager and graph)\n",
    "tf.config.run_functions_eagerly(True)  # Enable eager mode\n",
    "x = tf.constant([1, 2, 3])\n",
    "y = x + 2  # Immediate execution\n",
    "```\n",
    "\n",
    "3. API Design:\n",
    "```python\n",
    "# PyTorch (Object-Oriented)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# TensorFlow (More functional)\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(5, activation='relu', input_shape=(10,)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "```\n",
    "\n",
    "The main philosophical differences are:\n",
    "- PyTorch is more Python-native and research-friendly\n",
    "- TensorFlow is more production-focused with better deployment tools\n",
    "- PyTorch has a more imperative style\n",
    "- TensorFlow has better visualization tools (TensorBoard)\n",
    "- PyTorch has better debugging capabilities due to its dynamic nature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
